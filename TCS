Linux Admin
1.LvM
*** How to Copy and how to take backups ***

*** ping server is not reachable(what is the next step)***
‚úÖ If ping is not reachable, next steps:
Check if the server is up
ssh <server-ip>

Check DNS issue
Try pinging IP instead of hostname:
ping <IP>
If IP works but hostname doesn't ‚Üí DNS problem.

Check if the network route exists-Want to check network path / routing issue
traceroute <IP>
This shows where the connection is breaking.

Check firewall / security rules
Linux firewall:
sudo ufw status

Check if required port is reachable
telnet <IP> <port>
or
nc -zv <IP> <port>
Ping only checks ICMP, not application access.
Example: ping may fail but 443 could be open.
If SSH also fails ‚Üí server may be down or firewall blocking.


*** How to search using port number ***
1.Check open ports and listening services
sudo netstat -tulpn | grep <port-number>
Example:
sudo netstat -tulpn | grep 443

2.sing ss (modern replacement for netstat)
sudo ss -tulpn | grep <port-number>
Example:
sudo ss -tulpn | grep 22

nc
‚úÖ 1Ô∏è‚É£ Using nc (netcat)
We use nc to check if a specific port is open or reachable on a server.
Test if a remote server port is open
nc -zv <server-ip> <port>
Example:
nc -zv 10.10.1.20 3306
or:
telnet <server-ip> <port>
Example:
telnet google.com 443



*** schedule job at 5 am and it has to delete the log files that are 10 days old ***
0 5 * * * find /var/log -type f -mtime +10 -name "*.log" -exec rm -f {} \;
üìò Explanation:
0 5 * * * ‚Üí Run daily at 05:00 AM
find ‚Üí searches in /var/log
-mtime +10 ‚Üí files older than 10 days
-exec rm -f {} ‚Üí delete each found file

Kuberenetes
*** Kubectl commmands ***
*** Image pull back off error ***
1Ô∏è‚É£ ImagePullBackOff Error
Meaning:
It means Kubernetes tried to pull (download) the container image from the image registry (like Docker Hub, Quay, or a private repo) but failed repeatedly.
Common Causes:
*Incorrect image name or tag
Example: nginx:alpinee (wrong spelling)
*Private image repository (authentication needed)
Missing imagePullSecret
*Network issue
Cluster node cannot connect to Docker registry.
*DNS issue
Node cannot resolve the registry hostname.

How to check:
kubectl describe pod <pod-name>

Look at the Events section; you‚Äôll see messages like:
Failed to pull image "nginx:latest": rpc error: code = Unknown desc = Error response from daemon


Fix:
‚úÖ Check the image name and tag
‚úÖ If private registry ‚Üí create secret:
kubectl create secret docker-registry myregistrykey \
  --docker-server=<registry-url> \
  --docker-username=<username> \
  --docker-password=<password> \
  --docker-email=<email>
Then in Pod YAML:
imagePullSecrets:
  - name: myregistrykey
‚úÖ Check node network/DNS using:
kubectl get nodes -o wide
kubectl exec -it <pod> -- nslookup <registry-url>

****Pod pending state****
A Pod in Pending state means Kubernetes accepted the request but hasn‚Äôt been able to schedule the Pod onto any node.
It is basically stuck before running.
‚úÖ Why a Pod goes into Pending State?
Here are the most common reasons with simple explanation:
| Reason                                                             | Meaning                                          | Example                                                          |
| ------------------------------------------------------------------ | ------------------------------------------------ | ---------------------------------------------------------------- |
| **Not enough CPU/Memory resources**                                | No node has free capacity to run the pod         | You requested `2 CPU and 4Gi memory`, but all nodes are full     |
| **No node matches nodeSelector/taints/tolerations/affinity rules** | Scheduling rules block the pod from being placed | Pod demands a node with label `env=prod` but no such node exists |
| **PVC (Persistent Volume Claim) not bound**                        | Storage request not available yet                | Your PVC is Pending ‚Üí Pod also Pending                           |
| **ImagePullSecret missing for private registry**                   | Kubernetes can‚Äôt access private image            | Works only after you configure a secret                          |
| **Network policy / permissions issue**                             | Scheduler can't assign pod due to constraints    | Rare but possible                                                |

üß™ How to Troubleshoot Step-by-Step
1Ô∏è‚É£ Check Pod Status and Events
kubectl describe pod <pod-name>
Look at the bottom: Events section ‚Äî it tells the real reason.

2Ô∏è‚É£ Check if Resources are Available
kubectl get nodes -o wide
kubectl describe node <node-name>
If you see messages like:
0/3 nodes are available: insufficient memory / cpu
Then your requests are too high.
3Ô∏è‚É£ Check PVC Binding Issue
kubectl get pvc
If PVC is also Pending, fix storage before the pod runs.
4Ô∏è‚É£ Check Scheduling Rules
If you're using labels or taints:
kubectl get nodes --show-labels
kubectl describe node <node>
‚≠ê Common scheduler mismatch messages:
node(s) didn't match node selector
node(s) had taints that the pod didn't tolerate
üõ† Example Real-Life Issue
YAML:
resources:
  requests:
    cpu: "2"
    memory: "4Gi"
If your node has only 1 CPU free, scheduler won't assign it, so pod stays pending.

ü©π Fix: lower the request:
resources:
  requests:
    cpu: "0.5"
    memory: "512Mi"
Adjust the reource requests and limits in the deployment
kubectl edit deployment <deployment-name>


***node not ready(all the nodes in the cluster are not ready)***
It means Kubernetes cannot talk to the node, so pods cannot run on it.
üìå How to Check Node Status
kubectl get nodes
Example output:
NAME       STATUS     ROLES    AGE     VERSION
node01     NotReady   worker   20d     v1.28
node02     NotReady   worker   20d     v1.28

üõ† How to Fix It (Simple Steps)
1Ô∏è‚É£ Check kubelet is running
Describe the Node
kubectl describe node <node-name>
Look for messages under Conditions:
Ready: False
Reason: KubeletNotReady
Message: container runtime is down

2Ô∏è‚É£ SSH into the node and check Kubelet
systemctl status kubelet
If not running, start it:
sudo systemctl start kubelet
sudo systemctl enable kubelet

3Ô∏è‚É£ Check Node Pressure (Memory, Disk)
Node Pressure means the node is running low on memory or disk space, so Kubernetes marks it as NotReady to protect itself.

Types of Pressure:
| Pressure Type      | Meaning                             | Example                              |
| ------------------ | ----------------------------------- | ------------------------------------ |
| **MemoryPressure** | Node is running out of RAM          | Too many pods using memory           |
| **DiskPressure**   | Node is running out of disk storage | Logs, images, or files fill the disk |

üß™ How to Check?
Run:
kubectl describe node <node-name>
If you see:
MemoryPressure: True
DiskPressure: True

üõ† How to Fix Node Pressure (Simple Steps)
‚úÖ If Memory is Low
The node doesn't have enough RAM.
Fix: Remove extra pods or increase the size of the node.

‚úÖ If Disk is Full
The node doesn't have enough storage.
Fix: Delete old files, logs, and unused container images.

üßπ Simple Cleanup Commands
If using Docker:
docker system prune -a
If using containerd:
crictl rmi --prune



*** service not reachable, how to troubleshoot ***
üö® When a Service is Not Reachable
It means traffic is not passing from:
Client ‚Üí Service ‚Üí Pod

üß™ Step-by-Step Troubleshooting (Simple)
1Ô∏è‚É£ Check if Service Exists
kubectl get svc
Make sure service name and namespace are correct.

2Ô∏è‚É£ Check Service Type
kubectl describe svc <service-name>
Types:
| Type         | When used                                         |
| ------------ | ------------------------------------------------- |
| ClusterIP    | Inside cluster only                               |
| NodePort     | Accessible from outside using `<NodeIP>:NodePort` |
| LoadBalancer | Cloud access (AWS/Azure/GCP)                      |
If you're trying to access a ClusterIP from outside the cluster, it won't work.

3Ô∏è‚É£ Check if Service Has Endpoints
For a Service to send traffic to a Pod, the labels on the Pod must match the selector in the Service. If they don‚Äôt match, the Service has no endpoints, and traffic won‚Äôt reach the Pod.
What are "Endpoints"?
Endpoints are the IP addresses of pods that a service will send traffic to.
If a service has no endpoints, it means:
The service does not know which pod it should talk to.

üí° Why does this happen?
Because Kubernetes finds pods based on labels.
A Service has a selector, and it looks for pods with matching labels.

üß† Example to Understand
‚úÖ Service YAML:
selector:
  app: web
This means:
"Send traffic only to pods that have the label app=web".

‚ùå Pod Labels (incorrect)
labels:
  app: backend

Since app=backend ‚â† app=web, the service will find zero pods.
So endpoints will be:
<none>
‚úî Pod Labels (correct)
labels:
  app: web

Now labels match ‚Üí service will find the pod ‚Üí endpoints will be created.
üõ† How to Check
1Ô∏è‚É£ Check service selector:
kubectl describe svc <service-name>
You will see something like:
Selector: app=web

2Ô∏è‚É£ Check pod labels:
kubectl get pods --show-labels
Example output:
pod1   Running   app=backend
pod2   Running   app=web
Only the pod with app=web will become an endpoint.

5Ô∏è‚É£ Check Pod is Running and Ready
kubectl get pods
If pod is:
CrashLoopBackOff
Error
Pending
‚Üí Service cannot route traffic.

6Ô∏è‚É£ Test Inside Cluster
Use busybox or curl pod:
kubectl run test --image=busybox:1.28 -it -- /bin/sh

Then test:
curl http://<service-name>:<port>
If this works but external access fails ‚Üí issue is NodePort / LoadBalancer.

7Ô∏è‚É£ Check Firewall / NodePort Access
If using NodePort:
curl <NodeIP>:<NodePort>
If blocked ‚Üí firewall or security group issue.

5.What is Service and types of services
*** what is pv and pvc?what happens if pod is deleted to pvc-perisitenceVolumeReclaimPolicy and command to check pv and pvc? ***
| Object  | Meaning             |
| ------- | ------------------- |
| **PV**  | The actual storage  |
| **PVC** | Request for storage |

üîÅ What happens if a Pod is deleted?
The Pod is deleted, but the PVC and PV remain.
So when a new pod comes back using the same PVC ‚Üí it can still access the same data.

üóë What happens when PVC is deleted?
This depends on the Reclaim Policy of the PV.

üìå PersistenceVolumeReclaimPolicy Types
| Policy            | Meaning        | What happens when PVC is deleted         |
| ----------------- | -------------- | ---------------------------------------- |
| **Retain**        | Keep data safe | PV keeps data; admin must clean manually |
| **Delete**        | Delete storage | PV and actual storage are deleted        |
| **Recycle (old)** | Wipes data     | Not used in modern Kubernetes            |

üß† Simple Example:
If policy = Retain
Pod deleted ‚Üí data still there
‚úî When PVC is deleted
The PVC (request) is gone.
But the PV and data are NOT deleted.
Kubernetes marks the PV as:
Released

This means:
‚ÄúThe data still exists, but Kubernetes won‚Äôt reuse it automatically until an admin cleans or resets it.‚Äù

If policy = Delete
PVC deleted ‚Üí PV + data removed forever

üß™ Commands to Check PV and PVC
Check all PVs:
kubectl get pv

Check details of a specific PV:
kubectl describe pv <pv-name>

Check all PVCs:
kubectl get pvc

Check details of a specific PVC:
kubectl describe pvc <pvc-name>
üëâ This is how data remains safe even if the pod restarts or crashes.


*** progressdeadline error-we can increase the replicas pods ***
we can use autoscaling Hpa(to increase pods) and vpa(to cpu and memory for existing pods)

üö® What is a ProgressDeadlineExceeded error?
This error happens when a Deployment takes too long to become Ready.
Kubernetes waits for a certain time (default 10 minutes).
If pods are not running and healthy within that time, Kubernetes shows:
ProgressDeadlineExceeded

üîç Why does it happen?
Common reasons:
New pods failing to start
Image pull error
Readiness/Liveness probe failing
Not enough CPU/Memory
Too few replicas for load

üõ† How to Fix It (Simple)
‚úÖ 1Ô∏è‚É£ Increase Replica Count
If the application needs more pods to handle traffic:
kubectl scale deploy <deployment-name> --replicas=5
This adds more pods manually.

‚úÖ 2Ô∏è‚É£ Use HPA (Horizontal Pod Autoscaler)
This automatically increases or decreases pod count based on CPU, memory, or custom metrics.
Example:
kubectl autoscale deployment <deployment-name> --cpu-percent=50 --min=2 --max=10
Meaning:
If CPU goes above 50%, Kubernetes will automatically create more pods (up to 10).
‚úÖ 3Ô∏è‚É£ Use VPA (Vertical Pod Autoscaler)

This adjusts CPU and memory of existing pods, instead of creating more pods.
Useful when pods are crashing due to insufficient resources.
Example install-based command:
VPA will recommend or auto adjust resources.
(Not a single CLI command ‚Äî requires CRDs enabled.)


*** Kubernetes architecture ***
üß† 1Ô∏è‚É£ Control Plane (Master components)-decides where your application should run and monitors the health of the application
These components manage and control the cluster.
| Component              | Simple Meaning                                             |
| ---------------------- | ---------------------------------------------------------- |
| **API Server**         | Entry point for all Kubernetes commands (kubectl talks to this)         |
| **etcd**               | Database that stores all cluster data (state).             |
| **Scheduler**          | Decides which node should run a pod.                       |
| **Controller Manager** | Ensures desired state (e.g., keeps replica count correct). |

üñ•Ô∏è 2Ô∏è‚É£ Worker Nodes
These nodes run the actual applications (pods).
| Component                                 | Simple Meaning                                |
| ----------------------------------------- | --------------------------------------------- |
| **Kubelet**                               | Agent on each node that manages pods.         |
| **Container Runtime (Docker/containerd)** | Runs containers.                              |
| **Kube-Proxy**                            | Manages networking and service communication. ,and rouete trafice to the right pods|

üì¶ Pods
Smallest running unit in Kubernetes.
Runs one or more containers.

üèó Deployment
Defines how many pods should run.
Kubernetes ensures they remain running.

üåê Service
Provides a stable network endpoint to access pods.

kubectl apply -f deployment.yaml
API Server receives request.
Scheduler decides the best worker node.
Kubelet on that node creates the pod.
Container Runtime starts the container.
Kube-Proxy helps networking so pod can communicate.



*** you are using external ip not reachable? ans-network policies????not sure ***
External IP is not reachable because the traffic is blocked somewhere ‚Äî check service type, endpoints, network policy, and firewall rules.
üõ† Quick Troubleshooting Steps

1Ô∏è‚É£ Check service type
kubectl get svc
If type is ClusterIP, external access won‚Äôt work.

2Ô∏è‚É£ Check endpoints
kubectl get endpoints <service-name>
If empty ‚Üí fix labels.

3Ô∏è‚É£ Check network policies
kubectl get networkpolicy
If policies exist, they may block inbound traffic.

4Ô∏è‚É£ Check Node/Cloud Firewall
Open port if using NodePort (range: 30000‚Äì32767).

***How to increase cpu and memory to pod ?command ***
üîß How to Increase CPU and Memory for a Pod?
You cannot change resources directly on a running Pod.
Instead, you update the Deployment, StatefulSet, or ReplicaSet that manages the Pod.
Kubernetes will then restart the Pod with new resources.
üìç Example YAML Before:
resources:
  requests:
    cpu: "100m"
    memory: "256Mi"
  limits:
    cpu: "200m"
    memory: "512Mi"

üìç After Increasing:
resources:
  requests:
    cpu: "500m"
    memory: "512Mi"
  limits:
    cpu: "1"
    memory: "1Gi"

üõ† Apply Change:
If this is part of a Deployment file:
kubectl apply -f deployment.yaml
Kubernetes will recreate pods with the updated values.

üöÄ Quick Method (No YAML)
You can edit the deployment directly:
kubectl edit deployment <deployment-name>
Then modify:
resources:
  requests:
    cpu: "500m"
    memory: "512Mi"
  limits:
    cpu: "1"
    memory: "1Gi"
Save ‚Üí Pods restart with new CPU/Memory.

‚öôÔ∏è Using Autoscaling
üîπ HPA (Horizontal Pod Autoscaler) ‚Üí Increase Number of Pods
kubectl autoscale deployment <deployment-name> --cpu-percent=50 --min=2 --max=5
üîπ VPA (Vertical Pod Autoscaler) ‚Üí Automatically adjust CPU/Memory
(If installed)
kubectl apply -f vpa.yaml

*** we have pod in one namepspace wnat to  communicate with other other namespace?-namespace selector network policies,Rbac ***
‚ùì Can a Pod in one namespace communicate with a pod in another namespace?
üëâ Yes, by default Kubernetes allows cross-namespace communication.
You can access another pod using:
<service-name>.<namespace>.svc.cluster.local
Example:
curl http://app-service.dev.svc.cluster.local
But sometimes communication may not work because of:
üö´ 1Ô∏è‚É£ Network Policies
NetworkPolicies can block traffic between namespaces.
To allow communication, you can use a namespaceSelector.
Example Network Policy Allowing Traffic From Another Namespace üëá
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-from-dev
  namespace: prod
spec:
  podSelector: {} 
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          allowed: "true"

Then label the allowed namespace:
kubectl label namespace dev allowed=true
üö´ 2Ô∏è‚É£ RBAC Permissions
Even if network allows communication, some operations (like list pods, exec, logs) may require RBAC access.
Example RoleBinding to allow a service account from namespace dev to access resources in prod:

apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: allow-dev-access
  namespace: prod
subjects:
- kind: ServiceAccount
  name: app-sa
  namespace: dev
roleRef:
  kind: Role
  name: view
  apiGroup: rbac.authorization.k8s.io


*** In your project how you are using RBAC ***
Example:
| Role                      | What They Can Do                                                    |
| ------------------------- | ------------------------------------------------------------------- |
| **Admin**                 | Full control of the cluster                                         |
| **Developer**             | Can view pods, logs, and update deployments only in their namespace |
| **Tester/QA**             | Read-only access (cannot edit or delete anything)                   |
| **CI/CD Service Account** | Can deploy applications but cannot delete cluster resources         |

üí¨ How I use RBAC in my project
In my project, RBAC (Role-Based Access Control) is used to control who can do what inside the Kubernetes cluster.
We don‚Äôt give full admin access to everyone ‚Äî instead, we give permissions based on roles.

üß† Why we use RBAC?
To avoid accidental deletion of resources
To enforce least privilege principle
To make the cluster secure

üõ† How we configure RBAC
We create:
Role or ClusterRole ‚Üí defines permissions
RoleBinding or ClusterRoleBinding ‚Üí assigns the role to a user, group, or service account

üìå Example we use in our environment:
Role: Allow developers to manage deployments only
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: dev-role
  namespace: dev
rules:
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "watch", "create", "update"]

RoleBinding: Assign role to developer team
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: dev-binding
  namespace: dev
subjects:
- kind: User
  name: developer1
roleRef:
  kind: Role
  name: dev-role
  apiGroup: rbac.authorization.k8s.io

üîê Service Account Usage
Our CI/CD pipeline runs with a Service Account that has limited permissions.
It can:
Deploy application
Update secrets
Manage ConfigMaps
but cannot delete namespaces or cluster-level resources.


Docker
1.what is docker file?and what are the main instructions or components in docker file?from that docker file how to create image and container
2.how to delete the container that was stopped?
first check docker ps -a-status of container
docker images
docker rmi container <containerid>


